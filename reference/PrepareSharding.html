<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>############################################### #' Take debarcoded reads and split them into suitable numbers of shards. #' #' The reads from one cell is guaranteed to only be present in a single shard. #' This makes parallel processing simple as each shard can be processed on #' a separate computer. Using more shards means that more computers can be used. #' #' If you perform all the calculations on a single computer, having more #' than one shard will not result in a speedup. This option is only relevant #' when using a cluster of compute nodes. #' #' #' #' TODO if we have multiple input samples, is there a way to group them? #' otherwise we will be reading more input files than needed. that said, #' if we got an index, so if list of cells specified, it is possible to quickly figure out #' out if a file is needed at all for a merge #' #' TODO Figuring out if a file is needed can be done at "planning" (Zorn) stage #' #' TODO seems faster to have a single merger that writes multiple output files if #' cell list is not provided. if the overhead is accepted then read all input files and #' discard cells on the fly #' #' @param inputName Name of input file: Debarcoded reads #' @param outputName Name of the output file: Properly sharded debarcoded reads #' #' @return A job to be executed, or being executed, depending on runner settings #' @export BascetShardifyOld &lt;- function( bascetRoot, inputName="debarcoded", includeCells=NULL, ############# TODO: get rid of this parameter; only support direct merging numOutputShards=1, outputName="filtered", overwrite=FALSE, runner=GetDefaultBascetRunner(), bascetInstance=GetDefaultBascetInstance() ) input_shards &lt;- detectShardsForFile(bascetRoot, inputName) if(length(input_shards)==0) stop("Found no input files") #Include all cells if nothing else provided if(is.null(includeCells)) includeCells &lt;- BascetCellNames(bascetRoot, inputName, bascetInstance=bascetInstance) includeCells &lt;- unique(includeCells$cell) #when shardifying, we expect cells to appear more than once – could warn for other commands! print(paste("Including all the",length(includeCells), "cells")) #Figure out which cell goes into which shard list_cell_for_shard &lt;- shellscriptSplitArrayIntoListRandomly(includeCells, numOutputShards) #Figure out input and output file names inputFiles &lt;- file.path(bascetRoot, input_shards) outputFiles &lt;- makeOutputShardNames(bascetRoot, outputName, "tirp.gz", numOutputShards) if(bascetCheckOverwriteOutput(outputFiles, overwrite)) #Produce the script and run the job RunJob( runner = runner, jobname = "Z_shardify", bascetInstance = bascetInstance, cmd = c( #shellscript_set_tempdir(bascetInstance), shellscriptMakeBashArray("files_out", outputFiles),  ### Abort early if needed if(!overwrite) shellscriptCancelJobIfFileExists("${files_out[$TASK_ID]}"), shellscriptMakeFilesExpander("CELLFILE", list_cell_for_shard), paste( bascetInstance@prependCmd, bascetInstance@bin, "shardify", "-t $BASCET_TEMPDIR", "-i",shellscriptMakeCommalist(inputFiles), #Need to give all input files for each job "-o ${files_out[$TASK_ID]}", #Each job produces a single output "--cells=$CELLFILE" #Each job takes its own list of cells ), "rm $CELLFILE" ), arraysize = numOutputShards )  else new_no_job() Prepare to shard reads by collecting statistics about each barcode, and filtering out cells with few reads — PrepareSharding • Zorn</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="############################################### #' Take debarcoded reads and split them into suitable numbers of shards. #' #' The reads from one cell is guaranteed to only be present in a single shard. #' This makes parallel processing simple as each shard can be processed on #' a separate computer. Using more shards means that more computers can be used. #' #' If you perform all the calculations on a single computer, having more #' than one shard will not result in a speedup. This option is only relevant #' when using a cluster of compute nodes. #' #' #' #' TODO if we have multiple input samples, is there a way to group them? #' otherwise we will be reading more input files than needed. that said, #' if we got an index, so if list of cells specified, it is possible to quickly figure out #' out if a file is needed at all for a merge #' #' TODO Figuring out if a file is needed can be done at " planning stage todo seems faster to have a single merger that writes multiple output files if cell list is not provided. the overhead accepted then read all input and discard cells on fly inputname name of file: debarcoded reads outputname properly sharded job be executed or being depending runner settings bascetshardifyold function bascetroot includecells="NULL," todo: get rid this parameter only support direct merging numoutputshards="1," overwrite="FALSE," bascetinstance="GetDefaultBascetInstance()" input_shards detectshardsforfile stop no nothing else provided bascetcellnames unique shardifying we expect appear more than once could warn for other commands print out which goes into shard list_cell_for_shard shellscriptsplitarrayintolistrandomly file names inputfiles file.path outputfiles makeoutputshardnames script run runjob jobname="Z_shardify" cmd="c(" shellscriptmakebasharray abort early needed shellscriptcanceljobiffileexists shellscriptmakefilesexpander paste give each produces takes its own arraysize="numOutputShards" new_no_job prepare by collecting statistics about barcode filtering with few preparesharding><meta name="description" content="###############################################
#' Take debarcoded reads and split them into suitable numbers of shards.
#'
#' The reads from one cell is guaranteed to only be present in a single shard.
#' This makes parallel processing simple as each shard can be processed on
#' a separate computer. Using more shards means that more computers can be used.
#'
#' If you perform all the calculations on a single computer, having more
#' than one shard will not result in a speedup. This option is only relevant
#' when using a cluster of compute nodes.
#'
#'
#'
#' TODO if we have multiple input samples, is there a way to group them?
#' otherwise we will be reading more input files than needed. that said,
#' if we got an index, so if list of cells specified, it is possible to quickly figure out
#' out if a file is needed at all for a merge
#'
#' TODO Figuring out if a file is needed can be done at &quot;planning&quot; (Zorn) stage
#'
#' TODO seems faster to have a single merger that writes multiple output files if
#' cell list is not provided. if the overhead is accepted then read all input files and
#' discard cells on the fly
#'
#' @param inputName Name of input file: Debarcoded reads
#' @param outputName Name of the output file: Properly sharded debarcoded reads
#'
#' @return A job to be executed, or being executed, depending on runner settings
#' @export
BascetShardifyOld &amp;lt;- function(
bascetRoot,
inputName=&quot;debarcoded&quot;,
includeCells=NULL, ############# TODO: get rid of this parameter; only support direct merging
numOutputShards=1,
outputName=&quot;filtered&quot;,
overwrite=FALSE,
runner=GetDefaultBascetRunner(),
bascetInstance=GetDefaultBascetInstance()
)input_shards &amp;lt;- detectShardsForFile(bascetRoot, inputName)
if(length(input_shards)==0)
stop(&quot;Found no input files&quot;)#Include all cells if nothing else provided
if(is.null(includeCells))
includeCells &amp;lt;- BascetCellNames(bascetRoot, inputName, bascetInstance=bascetInstance)
includeCells &amp;lt;- unique(includeCells$cell) #when shardifying, we expect cells to appear more than once  – could warn for other commands!
print(paste(&quot;Including all the&quot;,length(includeCells), &quot;cells&quot;))#Figure out which cell goes into which shard
list_cell_for_shard &amp;lt;- shellscriptSplitArrayIntoListRandomly(includeCells, numOutputShards)#Figure out input and output file names
inputFiles &amp;lt;- file.path(bascetRoot, input_shards)
outputFiles &amp;lt;- makeOutputShardNames(bascetRoot, outputName, &quot;tirp.gz&quot;, numOutputShards)if(bascetCheckOverwriteOutput(outputFiles, overwrite))
#Produce the script and run the job
RunJob(
runner = runner,
jobname = &quot;Z_shardify&quot;,
bascetInstance = bascetInstance,
cmd = c(
#shellscript_set_tempdir(bascetInstance),
shellscriptMakeBashArray(&quot;files_out&quot;, outputFiles),    ### Abort early if needed
    if(!overwrite) shellscriptCancelJobIfFileExists(&quot;${files_out[$TASK_ID]}&quot;),    shellscriptMakeFilesExpander(&quot;CELLFILE&quot;, list_cell_for_shard),
    paste(
      bascetInstance@prependCmd,
      bascetInstance@bin,
      &quot;shardify&quot;,
      &quot;-t $BASCET_TEMPDIR&quot;,
      &quot;-i&quot;,shellscriptMakeCommalist(inputFiles), #Need to give all input files for each job
      &quot;-o ${files_out[$TASK_ID]}&quot;,                 #Each job produces a single output
      &quot;--cells=$CELLFILE&quot;                          #Each job takes its own list of cells
    ),
    &quot;rm $CELLFILE&quot;
  ),
  arraysize = numOutputShards
)
 else
new_no_job()
Prepare to shard reads by collecting statistics about
each barcode, and filtering out cells with few reads"><meta property="og:description" content="###############################################
#' Take debarcoded reads and split them into suitable numbers of shards.
#'
#' The reads from one cell is guaranteed to only be present in a single shard.
#' This makes parallel processing simple as each shard can be processed on
#' a separate computer. Using more shards means that more computers can be used.
#'
#' If you perform all the calculations on a single computer, having more
#' than one shard will not result in a speedup. This option is only relevant
#' when using a cluster of compute nodes.
#'
#'
#'
#' TODO if we have multiple input samples, is there a way to group them?
#' otherwise we will be reading more input files than needed. that said,
#' if we got an index, so if list of cells specified, it is possible to quickly figure out
#' out if a file is needed at all for a merge
#'
#' TODO Figuring out if a file is needed can be done at &quot;planning&quot; (Zorn) stage
#'
#' TODO seems faster to have a single merger that writes multiple output files if
#' cell list is not provided. if the overhead is accepted then read all input files and
#' discard cells on the fly
#'
#' @param inputName Name of input file: Debarcoded reads
#' @param outputName Name of the output file: Properly sharded debarcoded reads
#'
#' @return A job to be executed, or being executed, depending on runner settings
#' @export
BascetShardifyOld &amp;lt;- function(
bascetRoot,
inputName=&quot;debarcoded&quot;,
includeCells=NULL, ############# TODO: get rid of this parameter; only support direct merging
numOutputShards=1,
outputName=&quot;filtered&quot;,
overwrite=FALSE,
runner=GetDefaultBascetRunner(),
bascetInstance=GetDefaultBascetInstance()
)input_shards &amp;lt;- detectShardsForFile(bascetRoot, inputName)
if(length(input_shards)==0)
stop(&quot;Found no input files&quot;)#Include all cells if nothing else provided
if(is.null(includeCells))
includeCells &amp;lt;- BascetCellNames(bascetRoot, inputName, bascetInstance=bascetInstance)
includeCells &amp;lt;- unique(includeCells$cell) #when shardifying, we expect cells to appear more than once  – could warn for other commands!
print(paste(&quot;Including all the&quot;,length(includeCells), &quot;cells&quot;))#Figure out which cell goes into which shard
list_cell_for_shard &amp;lt;- shellscriptSplitArrayIntoListRandomly(includeCells, numOutputShards)#Figure out input and output file names
inputFiles &amp;lt;- file.path(bascetRoot, input_shards)
outputFiles &amp;lt;- makeOutputShardNames(bascetRoot, outputName, &quot;tirp.gz&quot;, numOutputShards)if(bascetCheckOverwriteOutput(outputFiles, overwrite))
#Produce the script and run the job
RunJob(
runner = runner,
jobname = &quot;Z_shardify&quot;,
bascetInstance = bascetInstance,
cmd = c(
#shellscript_set_tempdir(bascetInstance),
shellscriptMakeBashArray(&quot;files_out&quot;, outputFiles),    ### Abort early if needed
    if(!overwrite) shellscriptCancelJobIfFileExists(&quot;${files_out[$TASK_ID]}&quot;),    shellscriptMakeFilesExpander(&quot;CELLFILE&quot;, list_cell_for_shard),
    paste(
      bascetInstance@prependCmd,
      bascetInstance@bin,
      &quot;shardify&quot;,
      &quot;-t $BASCET_TEMPDIR&quot;,
      &quot;-i&quot;,shellscriptMakeCommalist(inputFiles), #Need to give all input files for each job
      &quot;-o ${files_out[$TASK_ID]}&quot;,                 #Each job produces a single output
      &quot;--cells=$CELLFILE&quot;                          #Each job takes its own list of cells
    ),
    &quot;rm $CELLFILE&quot;
  ),
  arraysize = numOutputShards
)
 else
new_no_job()
Prepare to shard reads by collecting statistics about
each barcode, and filtering out cells with few reads"></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">Zorn</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.4.3</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item"><a class="nav-link" href="../articles/install.html">Install</a></li>
<li class="nav-item"><a class="nav-link" href="../articles/get_started.html">Get started</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-vignettes" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Vignettes</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-vignettes"><li><h6 class="dropdown-header" data-toc-skip>Introductory Vignettes</h6></li>
    <li><a class="dropdown-item" href="../articles/slurm.html">Using SLURM</a></li>
    <li><a class="dropdown-item" href="../articles/debarcoding.html">Debarcoding</a></li>
    <li><a class="dropdown-item" href="../articles/read_quality_control.html">Read-based quality control</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><a class="dropdown-item" href="../articles/kraken.html">KRAKEN-based workflow</a></li>
    <li><a class="dropdown-item" href="../articles/alignment.html">Alignment-based workflow</a></li>
    <li><a class="dropdown-item" href="../articles/kmer.html">Informative KMER-based workflow</a></li>
    <li><a class="dropdown-item" href="../articles/countsketch.html">Count sketch KMER-based workflow</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><a class="dropdown-item" href="../articles/clustering.html">Clustering</a></li>
    <li><a class="dropdown-item" href="../articles/assembly.html">De novo assembly</a></li>
    <li><a class="dropdown-item" href="../articles/genome_annotation.html">Genome annotation</a></li>
    <li><a class="dropdown-item" href="../articles/snp_analysis.html">SNP analysis</a></li>
    <li><a class="dropdown-item" href="../articles/map_scripts.html">Map scripts</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><a class="dropdown-item" href="../articles/fileformats.html">Overview of file formats</a></li>
    <li><a class="dropdown-item" href="../articles/bascet_files.html">Working with Bascet files</a></li>
    <li><a class="dropdown-item" href="../articles/for_developers.html">For developers</a></li>
    <li><a class="dropdown-item" href="../articles/example_data.html">Example data</a></li>
  </ul></li>
<li class="nav-item"><a class="nav-link" href="../articles/faq.html">FAQ</a></li>
<li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><a class="external-link nav-link" href="https://henlab.org/" aria-label="Lab website"><span class="fa fa-home"></span></a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/henriksson-lab/zorn" aria-label="GitHub repository"><span class="fa fa-github"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>############################################### #' Take debarcoded reads and split them into suitable numbers of shards. #' #' The reads from one cell is guaranteed to only be present in a single shard. #' This makes parallel processing simple as each shard can be processed on #' a separate computer. Using more shards means that more computers can be used. #' #' If you perform all the calculations on a single computer, having more #' than one shard will not result in a speedup. This option is only relevant #' when using a cluster of compute nodes. #' #' #' #' TODO if we have multiple input samples, is there a way to group them? #' otherwise we will be reading more input files than needed. that said, #' if we got an index, so if list of cells specified, it is possible to quickly figure out #' out if a file is needed at all for a merge #' #' TODO Figuring out if a file is needed can be done at "planning" (Zorn) stage #' #' TODO seems faster to have a single merger that writes multiple output files if #' cell list is not provided. if the overhead is accepted then read all input files and #' discard cells on the fly #' #' @param inputName Name of input file: Debarcoded reads #' @param outputName Name of the output file: Properly sharded debarcoded reads #' #' @return A job to be executed, or being executed, depending on runner settings #' @export BascetShardifyOld &lt;- function( bascetRoot, inputName="debarcoded", includeCells=NULL, ############# TODO: get rid of this parameter; only support direct merging numOutputShards=1, outputName="filtered", overwrite=FALSE, runner=GetDefaultBascetRunner(), bascetInstance=GetDefaultBascetInstance() ) input_shards &lt;- detectShardsForFile(bascetRoot, inputName) if(length(input_shards)==0) stop("Found no input files") #Include all cells if nothing else provided if(is.null(includeCells)) includeCells &lt;- BascetCellNames(bascetRoot, inputName, bascetInstance=bascetInstance) includeCells &lt;- unique(includeCells$cell) #when shardifying, we expect cells to appear more than once – could warn for other commands! print(paste("Including all the",length(includeCells), "cells")) #Figure out which cell goes into which shard list_cell_for_shard &lt;- shellscriptSplitArrayIntoListRandomly(includeCells, numOutputShards) #Figure out input and output file names inputFiles &lt;- file.path(bascetRoot, input_shards) outputFiles &lt;- makeOutputShardNames(bascetRoot, outputName, "tirp.gz", numOutputShards) if(bascetCheckOverwriteOutput(outputFiles, overwrite)) #Produce the script and run the job RunJob( runner = runner, jobname = "Z_shardify", bascetInstance = bascetInstance, cmd = c( #shellscript_set_tempdir(bascetInstance), shellscriptMakeBashArray("files_out", outputFiles), <div class="sourceCode"><pre><code><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a> <span class="do">### Abort early if needed if(!overwrite) shellscriptCancelJobIfFileExists("${files_out[$TASK_ID]}"), shellscriptMakeFilesExpander("CELLFILE", list_cell_for_shard), paste( bascetInstance@prependCmd, bascetInstance@bin, "shardify", "-t $BASCET_TEMPDIR", "-i",shellscriptMakeCommalist(inputFiles), #Need to give all input files for each job "-o ${files_out[$TASK_ID]}", #Each job produces a single output "--cells=$CELLFILE" #Each job takes its own list of cells ), "rm $CELLFILE" ), arraysize = numOutputShards ) </span></span></code></pre></div> else new_no_job() Prepare to shard reads by collecting statistics about each barcode, and filtering out cells with few reads</h1>
      <small class="dont-index">Source: <a href="https://github.com/henriksson-lab/zorn/blob/main/R/debarcoding.R" class="external-link"><code>R/debarcoding.R</code></a></small>
      <div class="d-none name"><code>PrepareSharding.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>###############################################
#' Take debarcoded reads and split them into suitable numbers of shards.
#'
#' The reads from one cell is guaranteed to only be present in a single shard.
#' This makes parallel processing simple as each shard can be processed on
#' a separate computer. Using more shards means that more computers can be used.
#'
#' If you perform all the calculations on a single computer, having more
#' than one shard will not result in a speedup. This option is only relevant
#' when using a cluster of compute nodes.
#'
#'
#'
#' TODO if we have multiple input samples, is there a way to group them?
#' otherwise we will be reading more input files than needed. that said,
#' if we got an index, so if list of cells specified, it is possible to quickly figure out
#' out if a file is needed at all for a merge
#'
#' TODO Figuring out if a file is needed can be done at "planning" (Zorn) stage
#'
#' TODO seems faster to have a single merger that writes multiple output files if
#' cell list is not provided. if the overhead is accepted then read all input files and
#' discard cells on the fly
#'
#' @param inputName Name of input file: Debarcoded reads
#' @param outputName Name of the output file: Properly sharded debarcoded reads
#'
#' @return A job to be executed, or being executed, depending on runner settings
#' @export
BascetShardifyOld &lt;- function(
bascetRoot,
inputName="debarcoded",
includeCells=NULL, ############# TODO: get rid of this parameter; only support direct merging
numOutputShards=1,
outputName="filtered",
overwrite=FALSE,
runner=GetDefaultBascetRunner(),
bascetInstance=GetDefaultBascetInstance()
)input_shards &lt;- detectShardsForFile(bascetRoot, inputName)
if(length(input_shards)==0)
stop("Found no input files")#Include all cells if nothing else provided
if(is.null(includeCells))
includeCells &lt;- BascetCellNames(bascetRoot, inputName, bascetInstance=bascetInstance)
includeCells &lt;- unique(includeCells$cell) #when shardifying, we expect cells to appear more than once  – could warn for other commands!
print(paste("Including all the",length(includeCells), "cells"))#Figure out which cell goes into which shard
list_cell_for_shard &lt;- shellscriptSplitArrayIntoListRandomly(includeCells, numOutputShards)#Figure out input and output file names
inputFiles &lt;- file.path(bascetRoot, input_shards)
outputFiles &lt;- makeOutputShardNames(bascetRoot, outputName, "tirp.gz", numOutputShards)if(bascetCheckOverwriteOutput(outputFiles, overwrite))
#Produce the script and run the job
RunJob(
runner = runner,
jobname = "Z_shardify",
bascetInstance = bascetInstance,
cmd = c(
#shellscript_set_tempdir(bascetInstance),
shellscriptMakeBashArray("files_out", outputFiles),</p><div class="sourceCode"><pre><code><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a>    <span class="do">### Abort early if needed</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a>    <span class="cf">if</span>(<span class="sc">!</span>overwrite) <span class="fu">shellscriptCancelJobIfFileExists</span>(<span class="st">"${files_out[$TASK_ID]}"</span>),    <span class="fu">shellscriptMakeFilesExpander</span>(<span class="st">"CELLFILE"</span>, list_cell_for_shard),</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a>    <span class="fu">paste</span>(</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a>      bascetInstance<span class="sc">@</span>prependCmd,</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a>      bascetInstance<span class="sc">@</span>bin,</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a>      <span class="st">"shardify"</span>,</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>      <span class="st">"-t $BASCET_TEMPDIR"</span>,</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>      <span class="st">"-i"</span>,<span class="fu">shellscriptMakeCommalist</span>(inputFiles), <span class="co">#Need to give all input files for each job</span></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a>      <span class="st">"-o ${files_out[$TASK_ID]}"</span>,                 <span class="co">#Each job produces a single output</span></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a>      <span class="st">"--cells=$CELLFILE"</span>                          <span class="co">#Each job takes its own list of cells</span></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a>    ),</span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a>    <span class="st">"rm $CELLFILE"</span></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>  <span class="er">)</span>,</span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a>  arraysize <span class="ot">=</span> numOutputShards</span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a><span class="er">)</span></span></code></pre></div> else
new_no_job()
Prepare to shard reads by collecting statistics about
each barcode, and filtering out cells with few reads
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">PrepareSharding</span><span class="op">(</span></span>
<span>  <span class="va">bascetRoot</span>,</span>
<span>  inputName <span class="op">=</span> <span class="st">"debarcoded"</span>,</span>
<span>  minQuantile <span class="op">=</span> <span class="fl">0.5</span>,</span>
<span>  bascetInstance <span class="op">=</span> <span class="fu"><a href="GetDefaultBascetInstance.html">GetDefaultBascetInstance</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  verbose <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-bascetroot">bascetRoot<a class="anchor" aria-label="anchor" href="#arg-bascetroot"></a></dt>
<dd><p>The root folder where all Bascets are stored</p></dd>


<dt id="arg-inputname">inputName<a class="anchor" aria-label="anchor" href="#arg-inputname"></a></dt>
<dd><p>Name of input shard</p></dd>


<dt id="arg-minquantile">minQuantile<a class="anchor" aria-label="anchor" href="#arg-minquantile"></a></dt>
<dd><p>Read count-based cutoff for inclusion in final shards</p></dd>


<dt id="arg-bascetinstance">bascetInstance<a class="anchor" aria-label="anchor" href="#arg-bascetinstance"></a></dt>
<dd><p>A Bascet instance</p></dd>


<dt id="arg-verbose">verbose<a class="anchor" aria-label="anchor" href="#arg-verbose"></a></dt>
<dd><p>Print additional information, primarily to help troubleshooting</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>Statistics about the debarcoded reads</p>
    </div>

  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Johan Henriksson, Laura Carroll, Hadrien Gourlé, Julian Dicken, HenLab, CompMicroLab, and Collaborators.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer></div>





  </body></html>

